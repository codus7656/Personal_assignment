{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 한글 문서의 분류\n",
    "다음무비(http://movie.daum.net)로부터 crawl한 영화리뷰를 이용하여 분류 연습<br>\n",
    "영화리뷰와 영화의 제목을 학습해서 주어진 리뷰내용으로 어떤 영화에 대한 리뷰인지를 예측하고자 함\n",
    "### data file 내용\n",
    "'신과함께', '코코', '라라랜드', '인피니티 워', '곤지암' 다섯개의 영화에 대해 총 1827개의 리뷰를 수집\n",
    "csv 파일 안에 리뷰내용, 평점, 영화이름 의 순으로 저장되어 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "text = []\n",
    "y = []\n",
    "with open('movie_data.csv', encoding='utf-8') as csvfile:\n",
    "    csvreader = csv.reader(csvfile)\n",
    "    for row in csvreader:\n",
    "        #print(row)\n",
    "        if row: #그 줄에 내용이 있는 경우에만\n",
    "            text.append(row[0]) #영화 리뷰를 text 리스트에 추가\n",
    "            y.append(row[2]) #영화이름을 text 리스트에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of samples: 3653\n",
      "Movie titles of reivews: {'', '신과함께', '인피니티 워', '라라랜드', '코코', '곤지암'}\n"
     ]
    }
   ],
   "source": [
    "print('Num of samples: {}'.format(len(text)))\n",
    "print('Movie titles of reivews: {}'.format(set(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data and labels into a training and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(text, y, random_state=0)\n",
    "# 비율을 지정하지 않으면 75:25로 분할됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2739"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train) #1827의 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt #konlpy에서 Twitter 형태소 분석기를 import\n",
    "#from konlpy.tag import Twitter #konlpy에서 Twitter 형태소 분석기를 import\n",
    "twitter_tag = Okt()\n",
    "#twitter_tag = Twitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ㅜ', 'ㅜ']\n"
     ]
    }
   ],
   "source": [
    "print(twitter_tag.morphs(X_train[1])) #둘째 리뷰에 대해 형태소 단위로 tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_tag.nouns(X_train[1]) #둘째 리뷰에서 명사만 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twit_tokenizer(text): # Twitter 형태소 분석기의 명사추출함수를 tokenizer 함수로 사용\n",
    "    return twitter_tag.nouns(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score 0.8324205914567361\n",
      "Test score 0.7286652078774617\n",
      "(2739, 1180)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#tfidf = TfidfVectorizer(tokenizer=twit_tokenizer, min_df=3, max_df=0.90, max_features=1000, use_idf=True, sublinear_tf=True)\n",
    "tfidf = TfidfVectorizer(tokenizer=twit_tokenizer, min_df=2) #Twitter 형태소분석기에서 명사만 추출하는 함수를 tokenizer로 이용\n",
    "# twit_tokenizer 대신 twitter_tag.nouns를 직접 써도 됨\n",
    "# 하나의 문서에서만 출현한 단어는 쓸모가 없으므로 제외, 즉 최소 document frequency를 2로 설정\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train) # train data 변환 -> tfidf vector\n",
    "X_test_tfidf = tfidf.transform(X_test) # test data 변환 -> tfidf vector\n",
    "\n",
    "clf = LogisticRegression() # logistic regression 분류기 선언\n",
    "clf.fit(X_train_tfidf, y_train) # 분류기 학습\n",
    "print('Train score', clf.score(X_train_tfidf, y_train)) # train data 예측정확도\n",
    "print('Test score', clf.score(X_test_tfidf, y_test)) # test data 예측정확도\n",
    "print(X_train_tfidf.shape) # 총 1156개의 명사로 이루어짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '꼭봐야함 진심',\n",
       " '서릿발 같은 원한과 복수가 없으니 더 서늘하다.',\n",
       " '',\n",
       " '이 정도면,,,울 나라 영화 치고  상당히 잘 만들었다 생각한다.  몽조리,,허리웃에,,맛들어가지고,,참,, 평점이 너무 박하다.  나름,,공포지수는 상당했다.  빼어난 수작이다.   평점은,,,7,8점대나,,너무 박해서,,,10점 준다.  이상.',\n",
       " '예고편인줄 알면 안보러 갔을것',\n",
       " '',\n",
       " '역대급이었습니다 다음 2편 후속작도 기대하겠습니다',\n",
       " '',\n",
       " '아름답고, 따듯한 사후세계. 신과함께 보고 걸린 암이 나았습니다.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:10] #test data에서 앞 10개를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '', '인피니티 워', '', '곤지암', '', '', '인피니티 워', '', ''], dtype='<U6')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test_tfidf[:10]) # test data의 앞 10개에 대한 예측내용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '인피니티 워', '곤지암', '', '곤지암', '인피니티 워', '', '인피니티 워', '', '코코']\n"
     ]
    }
   ],
   "source": [
    "print(y_test[:10]) # test data 앞 10개의 실제 영화제목"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 성능을 개선하기 위한 노력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ㅜ', 'ㅜ']\n"
     ]
    }
   ],
   "source": [
    "# morphs()는 명사 외에도 모든 형태소를 포함\n",
    "print(twitter_tag.morphs(X_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score 0.8711208470244615\n",
      "Test score 0.7286652078774617\n",
      "(2739, 2302)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=twitter_tag.morphs, min_df=2) # 명사 대신 모든 형태소를 사용\n",
    "#tfidf = TfidfVectorizer(tokenizer=twit_tokenizer, min_df=3, max_df=0.90, max_features=1000, use_idf=True, sublinear_tf=True)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "print('Train score', clf.score(X_train_tfidf, y_train))\n",
    "print('Test score', clf.score(X_test_tfidf, y_test))\n",
    "print(X_train_tfidf.shape)\n",
    "#명사만 사용한 것에 비해 train score는 상승, test score는 하락"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ㅜ', 'KoreanParticle'), ('ㅜ', 'KoreanParticle')]\n"
     ]
    }
   ],
   "source": [
    "print(twitter_tag.pos(X_train[1], norm=True, stem=True)) #pos()는 형태소와 품사를 함께 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twit_tokenizer2(text): #전체를 다 사용하는 대신, 명사, 동사, 형용사를 사용\n",
    "    target_tags = ['Noun', 'Verb', 'Adjective']\n",
    "    result = []\n",
    "    for word, tag in twitter_tag.pos(text, norm=True, stem=True):\n",
    "        if tag in target_tags:\n",
    "            result.append(word)\n",
    "#            result.append('/'.join([word, tag]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(twit_tokenizer2(X_train[1])) # 사용 예"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score 0.8652792990142387\n",
      "Test score 0.7450765864332604\n",
      "(2739, 1598)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=twit_tokenizer2, min_df=2) #명사, 동사, 형용사를 이용하여 tfidf 생성\n",
    "#tfidf = TfidfVectorizer(tokenizer=twit_tokenizer, min_df=3, max_df=0.90, max_features=1000, use_idf=True, sublinear_tf=True)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "print('Train score', clf.score(X_train_tfidf, y_train))\n",
    "print('Test score', clf.score(X_test_tfidf, y_test))\n",
    "print(X_train_tfidf.shape)\n",
    "# 현재까지 중에서 test score가 가장 뛰어남"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 형태소를 다 사용하고 품사를 알 수 있도록 하면?\n",
    "def twit_tokenizer3(text):\n",
    "    #target_tags = ['Noun', 'Verb', 'Adjective']\n",
    "    result = []\n",
    "    for word, tag in twitter_tag.pos(text, norm=True, stem=True):\n",
    "        result.append('/'.join([word, tag])) #단어의 품사를 구분할 수 있도록 함\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score 0.8769623950346842\n",
      "Test score 0.7461706783369803\n",
      "(2739, 2034)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=twit_tokenizer3, min_df=2)\n",
    "#tfidf = TfidfVectorizer(tokenizer=twit_tokenizer, min_df=3, max_df=0.90, max_features=1000, use_idf=True, sublinear_tf=True)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "print('Train score', clf.score(X_train_tfidf, y_train))\n",
    "print('Test score', clf.score(X_test_tfidf, y_test))\n",
    "print(X_train_tfidf.shape)\n",
    "#성능이 오히려 떨어지고 품사 표시 없이 전체를 다 사용한 경우에 비해 train은 떨어지고, test는 올라감"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.959\n",
      "Test set score: 0.767\n"
     ]
    }
   ],
   "source": [
    "# train score가 높으므로 ridge를 쓰면 어떨까?\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "ridge_clf = RidgeClassifier(alpha = 1)\n",
    "ridge_clf.fit(X_train_tfidf, y_train)\n",
    "print('Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
    "print('Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))\n",
    "# train score가 올라가는 현상이 벌어짐\n",
    "# test score가 올라갔으나 명사, 형용사, 동사를 쓴 것보다 떨어짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.834\n",
      "Test set score: 0.751\n",
      "Used features count: 375 out of 2034\n"
     ]
    }
   ],
   "source": [
    "#lasso를 쓰면?\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "lasso_clf = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "lasso_clf.fit(X_train_tfidf, y_train)\n",
    "print('Train set score: {:.3f}'.format(lasso_clf.score(X_train_tfidf, y_train)))\n",
    "print('Test set score: {:.3f}'.format(lasso_clf.score(X_test_tfidf, y_test)))\n",
    "print('Used features count: {}'.format(np.sum(lasso_clf.coef_ != 0)), 'out of', X_train_tfidf.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0288389  0.01328703 0.01243155 0.01200763 0.01084746 0.00947385\n",
      " 0.00902128 0.00844526 0.00826019 0.0076784  0.00728165 0.00679249\n",
      " 0.00664239 0.00634816 0.00602749 0.00584802 0.00581584 0.00560971\n",
      " 0.00549236 0.00527034 0.00515977 0.00505914 0.00499327 0.00480125\n",
      " 0.00478183 0.00454265 0.00450766 0.00439897 0.00431664 0.00425505\n",
      " 0.00421284 0.00417336 0.00411537 0.00405579 0.00397664 0.00392832\n",
      " 0.0039006  0.00380968 0.00379675 0.00377991 0.0037198  0.00365839\n",
      " 0.00358171 0.00357179 0.00354034 0.00347207 0.00343077 0.00337938\n",
      " 0.00333398 0.00329826 0.00327249 0.00321609 0.00321032 0.00315627\n",
      " 0.00310886 0.00308762 0.00307204 0.0030458  0.00301332 0.0029981\n",
      " 0.00296195 0.00293069 0.0028688  0.00285055 0.0028344  0.00281693\n",
      " 0.00278754 0.00275978 0.00274434 0.00274162 0.00270626 0.00267445\n",
      " 0.00266058 0.00261217 0.00260722 0.00259654 0.00257639 0.00253159\n",
      " 0.0025145  0.00250239 0.00249813 0.00245706 0.00244653 0.00243859\n",
      " 0.00243555 0.00242538 0.00237339 0.00236423 0.00235229 0.00233466\n",
      " 0.00230228 0.00228534 0.00227315 0.00226096 0.00225561 0.00222584\n",
      " 0.0022162  0.00220391 0.00219271 0.0021732  0.00215613 0.00213767\n",
      " 0.00213566 0.00212575 0.00210878 0.00209598 0.00208445 0.00207814\n",
      " 0.00206638 0.00205348 0.00204395 0.00203104 0.00201837 0.00200887\n",
      " 0.00198253 0.00197698 0.00197176 0.00195154 0.00194684 0.00192637\n",
      " 0.00191457 0.00189878 0.00189408 0.00187811 0.00186312 0.00186001\n",
      " 0.0018521  0.00184157 0.00183688 0.00180822 0.0018041  0.00179396\n",
      " 0.00179317 0.00177909 0.00176357 0.0017592  0.00175411 0.00174097\n",
      " 0.00173455 0.00172799 0.00172388 0.00171461 0.00171198 0.00169169\n",
      " 0.00169115 0.00168114 0.00167352 0.00166386 0.00164449 0.00164248\n",
      " 0.00163551 0.00162807 0.00162337 0.00161442 0.00160649 0.00160458\n",
      " 0.00159397 0.00158717 0.00157565 0.00157067 0.00156313 0.00155432\n",
      " 0.00154318 0.00153916 0.00153707 0.00152613 0.00151987 0.001516\n",
      " 0.00150357 0.00150331 0.00149301 0.00148883 0.00147173 0.00146645\n",
      " 0.00146155 0.00145298 0.00144952 0.00144625 0.00144044 0.00143477\n",
      " 0.00142396 0.00141332 0.00140836 0.0014049  0.00140228 0.0013957\n",
      " 0.00139045 0.00138839 0.00138543 0.00137782 0.00136997 0.00135975\n",
      " 0.00135163 0.00134537 0.00134446 0.00133455 0.00133111 0.00132882\n",
      " 0.00131797 0.00131565 0.00131038 0.00130795 0.0012988  0.00129373\n",
      " 0.00129161 0.0012864  0.0012823  0.00127116 0.00126779 0.00126013\n",
      " 0.00125499 0.00124413 0.00124496 0.0012422  0.00123253 0.00123038\n",
      " 0.00122612 0.00121774 0.00121181 0.00120259 0.0011978  0.00119465\n",
      " 0.00118958 0.00118302 0.0011763  0.00116878 0.00116749 0.00116098\n",
      " 0.0011536  0.00114656 0.00114247 0.00113608 0.00113167 0.00112686\n",
      " 0.00111725 0.0011148  0.00110783 0.00109427 0.00108746]\n",
      "0.649300445312605\n",
      "[7.64833824 4.19193766 4.02410061 3.9553066  3.75891809 3.51726206\n",
      " 3.42899268 3.3176096  3.28029445 3.16253447 3.08084225 2.97472957\n",
      " 2.94433193 2.87553895 2.80415694 2.76823727 2.75226997 2.70311737\n",
      " 2.67466226 2.62090011 2.59290552 2.56800261 2.55028327 2.50070759\n",
      " 2.49583135 2.43257495 2.42306154 2.39382805 2.37200938 2.35422485\n",
      " 2.34264868 2.33496107 2.31520572 2.29846904 2.27587246 2.2625161\n",
      " 2.25401227 2.22935611 2.22408954 2.21918968 2.2011249  2.18294046\n",
      " 2.16155281 2.15699191 2.14791744 2.12738917 2.11393603 2.0983271\n",
      " 2.08385157 2.07283279 2.06563455 2.04686842 2.04491641 2.02787676\n",
      " 2.01239024 2.00597801 2.0008037  1.99176044 1.98113384 1.97610993\n",
      " 1.96420043 1.95375347 1.93305058 1.92791495 1.92227184 1.91568665\n",
      " 1.90549169 1.89623721 1.89063024 1.88968599 1.87746469 1.86639841\n",
      " 1.86170066 1.84459356 1.843563   1.83933493 1.83240105 1.81586853\n",
      " 1.8109225  1.80548553 1.80395805 1.7890801  1.78523933 1.78220098\n",
      " 1.78113665 1.77742202 1.75858091 1.75480984 1.75051751 1.74380811\n",
      " 1.73166773 1.72534964 1.72094976 1.71619446 1.71401795 1.70322758\n",
      " 1.69900315 1.69425895 1.68995337 1.68243908 1.67621993 1.66872963\n",
      " 1.66785032 1.66443011 1.65766925 1.65224946 1.64774955 1.64570852\n",
      " 1.64053768 1.63558331 1.63163589 1.62677321 1.62136649 1.61755876\n",
      " 1.60689493 1.60471249 1.60252386 1.594309   1.59236945 1.58398233\n",
      " 1.57910587 1.57263745 1.57063011 1.56399854 1.55781022 1.55643615\n",
      " 1.55315129 1.54884879 1.54691541 1.53459176 1.53288514 1.52882664\n",
      " 1.52826706 1.52233048 1.5154853  1.51356901 1.51177394 1.50574406\n",
      " 1.50316758 1.50006719 1.49879166 1.49428753 1.4932227  1.48463315\n",
      " 1.48389905 1.47955581 1.47624338 1.4722455  1.46333674 1.46272401\n",
      " 1.45936931 1.45602472 1.45380655 1.44994747 1.44629884 1.44528929\n",
      " 1.44056149 1.43751451 1.43230532 1.43007435 1.42645344 1.4226295\n",
      " 1.41739572 1.41551913 1.41461483 1.40948127 1.40652616 1.40481703\n",
      " 1.3990785  1.39893209 1.39421818 1.3920265  1.38412009 1.38173842\n",
      " 1.37932722 1.37519721 1.37305633 1.3722392  1.36905678 1.36646413\n",
      " 1.36106044 1.35633023 1.35371066 1.35164771 1.35065855 1.34744246\n",
      " 1.34520268 1.34403137 1.34221025 1.33895585 1.33501685 1.33023258\n",
      " 1.32541172 1.32272692 1.32232611 1.31710666 1.31628902 1.31464308\n",
      " 1.30935278 1.30778785 1.3048852  1.30364273 1.29940291 1.29654036\n",
      " 1.29638809 1.29295652 1.29101674 1.28542104 1.28414471 1.27934485\n",
      " 1.27727238 1.27225854 1.27155263 1.27052852 1.26536104 1.26392307\n",
      " 1.26233246 1.25735981 1.25412067 1.24875953 1.24774801 1.24557141\n",
      " 1.24264462 1.23964569 1.23532715 1.23217344 1.23080176 1.22796724\n",
      " 1.22276625 1.22047637 1.21734402 1.21375249 1.21134191 1.20834171\n",
      " 1.20356366 1.2026041  1.19811426 1.19112155 1.18739531]\n",
      "(239, 2034)\n"
     ]
    }
   ],
   "source": [
    "#lsa를 쓰면?\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=239, n_iter=7, random_state=42) #압축할 component의 수 지정\n",
    "svd.fit(X_train_tfidf)  \n",
    "print(svd.explained_variance_ratio_)  #계산된 각 component가 설명하는 분산의 비율\n",
    "print(svd.explained_variance_ratio_.sum())  #선택된 component들이 설명하는 분산의 합 -> 선택한 component의 수에 따라 달라짐\n",
    "print(svd.singular_values_) \n",
    "print(svd.components_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.834\n",
      "Test set score: 0.745\n"
     ]
    }
   ],
   "source": [
    "X_train_svd = svd.transform(X_train_tfidf) #선택된 component를 이용하여 2,000개의 feature로부터 feature extract (dimension reduce)\n",
    "X_test_svd = svd.transform(X_test_tfidf)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "SVD_clf = LogisticRegression()\n",
    "SVD_clf.fit(X_train_svd, y_train)\n",
    "print('Train set score: {:.3f}'.format(SVD_clf.score(X_train_svd, y_train)))\n",
    "print('Test set score: {:.3f}'.format(SVD_clf.score(X_test_svd, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chaeyeon\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:489: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set dimension: (2739, 1598)\n",
      "Test set dimension: (914, 1598)\n",
      "Train set score: 0.884\n",
      "Test set score: 0.790\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(tokenizer=twit_tokenizer2, min_df=2).fit(X_train) #tfidf와 동일하게 max_feature를 제한하여 학습\n",
    "X_train_cv = cv.transform(X_train) # train set을 변환\n",
    "print('Train set dimension:', X_train_cv.shape) # 36310 대신 2000이 된 것을 확인\n",
    "X_test_cv = cv.transform(X_test) # test set을 변환\n",
    "print('Test set dimension:', X_test_cv.shape)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "NB_clf = MultinomialNB()\n",
    "NB_clf.fit(X_train_cv, y_train)\n",
    "print('Train set score: {:.3f}'.format(NB_clf.score(X_train_cv, y_train)))\n",
    "print('Test set score: {:.3f}'.format(NB_clf.score(X_test_cv, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
